{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> [INDICIUM] - Processo Seletivo - Lighthouse Programa de Formação em Dados (Remoto) </center>\n",
    "    \n",
    "# <center> Treino e Teste do Modelo</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo: Identificar quais máquinas apresentam potencial de falha tendo como base dados extraídos através de sensores durante o processo de manufatura. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o tipo de rótulo é um dado discreto o tipo de modelo a ser utilzado será a classificação. Ao longo deste notebook serão descritas as etapas necessárias para atingir o objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import das libs necessárias no projeto\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#bliblotecas para a preparação do modelo\n",
    "from sklearn.model_selection import RepeatedKFold, KFold, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#import o classificador \n",
    "import lightgbm as lgb\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "#import label encoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from numpy import argmax \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "\n",
    "from pandasql import sqldf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler os dados do csv e transformar em um dataframe para possibilitar a sua manipulação\n",
    "df_treino = pd.read_csv(\"./desafio_manutencao_preditiva_treino.csv\")\n",
    "df_teste = pd.read_csv(\"./desafio_manutencao_preditiva_teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (6667, 9), test: (3333, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape train: %s, test: %s\" % (df_treino.shape, df_teste.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>udi</th>\n",
       "      <th>product_id</th>\n",
       "      <th>type</th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>M14865</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1425</td>\n",
       "      <td>41.9</td>\n",
       "      <td>11</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>L47186</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1558</td>\n",
       "      <td>42.4</td>\n",
       "      <td>14</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   udi product_id type  air_temperature_k  process_temperature_k  \\\n",
       "0    1     M14860    M              298.1                  308.6   \n",
       "1    2     L47181    L              298.2                  308.7   \n",
       "2    5     L47184    L              298.2                  308.7   \n",
       "3    6     M14865    M              298.1                  308.6   \n",
       "4    7     L47186    L              298.1                  308.6   \n",
       "\n",
       "   rotational_speed_rpm  torque_nm  tool_wear_min failure_type  \n",
       "0                  1551       42.8              0   No Failure  \n",
       "1                  1408       46.3              3   No Failure  \n",
       "2                  1408       40.0              9   No Failure  \n",
       "3                  1425       41.9             11   No Failure  \n",
       "4                  1558       42.4             14   No Failure  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualizar as cinco primeiras linhas do dataset de treino\n",
    "df_treino.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a análise explorartória tinha demonstrado não há dados nulos nas colunas, assim não é necessário nemhuma técnica de tratamento de dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "udi                      0\n",
      "product_id               0\n",
      "type                     0\n",
      "air_temperature_k        0\n",
      "process_temperature_k    0\n",
      "rotational_speed_rpm     0\n",
      "torque_nm                0\n",
      "tool_wear_min            0\n",
      "failure_type             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_treino.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Transformação e Preprocessamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 1: Criar outro dataframe com base no original para poder manipular os dados.\n",
    "\n",
    "Importante: Só serão copiados as colunas relevantes para o processo de transformação e treino do modelo. \n",
    "\n",
    "As colunas product_id e type não foram consideradas para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino_tf = df_treino[[\"air_temperature_k\", \"process_temperature_k\", \"rotational_speed_rpm\", \"torque_nm\", \"tool_wear_min\", \"failure_type\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "      <th>failure_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1425</td>\n",
       "      <td>41.9</td>\n",
       "      <td>11</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1558</td>\n",
       "      <td>42.4</td>\n",
       "      <td>14</td>\n",
       "      <td>No Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature_k  process_temperature_k  rotational_speed_rpm  torque_nm  \\\n",
       "0              298.1                  308.6                  1551       42.8   \n",
       "1              298.2                  308.7                  1408       46.3   \n",
       "2              298.2                  308.7                  1408       40.0   \n",
       "3              298.1                  308.6                  1425       41.9   \n",
       "4              298.1                  308.6                  1558       42.4   \n",
       "\n",
       "   tool_wear_min failure_type  \n",
       "0              0   No Failure  \n",
       "1              3   No Failure  \n",
       "2              9   No Failure  \n",
       "3             11   No Failure  \n",
       "4             14   No Failure  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#o novo dataframe de treino criado\n",
    "df_treino_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_tf = df_teste[[\"air_temperature_k\", \"process_temperature_k\", \"rotational_speed_rpm\", \"torque_nm\", \"tool_wear_min\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297.5</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1793</td>\n",
       "      <td>26.7</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300.7</td>\n",
       "      <td>310.5</td>\n",
       "      <td>1536</td>\n",
       "      <td>47.4</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297.2</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1460</td>\n",
       "      <td>42.1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299.4</td>\n",
       "      <td>309.1</td>\n",
       "      <td>1670</td>\n",
       "      <td>35.9</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304.1</td>\n",
       "      <td>313.1</td>\n",
       "      <td>1550</td>\n",
       "      <td>30.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature_k  process_temperature_k  rotational_speed_rpm  torque_nm  \\\n",
       "0              297.5                  308.6                  1793       26.7   \n",
       "1              300.7                  310.5                  1536       47.4   \n",
       "2              297.2                  308.4                  1460       42.1   \n",
       "3              299.4                  309.1                  1670       35.9   \n",
       "4              304.1                  313.1                  1550       30.9   \n",
       "\n",
       "   tool_wear_min  \n",
       "0             70  \n",
       "1            192  \n",
       "2             41  \n",
       "3             68  \n",
       "4              9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 2: Contar a quantidade por classe na coluna failure_type. Para atingir o problema essa coluna servirá como rótulos a serem inseridos no modelo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No Failure                  6435\n",
       "Heat Dissipation Failure      75\n",
       "Power Failure                 63\n",
       "Overstrain Failure            52\n",
       "Tool Wear Failure             30\n",
       "Random Failures               12\n",
       "Name: failure_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_tf[\"failure_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 3: Transformar a variável failure_type que é categórica em uma variável númerica. Os nomes serão transformados em números."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformar o y  \n",
    "#make an instance of Label Encoder\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "#transformando os dados de treino\n",
    "df_treino_tf[\"failure_type\"] = label_encoder.fit_transform(df_treino_tf[\"failure_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6435\n",
       "0      75\n",
       "3      63\n",
       "2      52\n",
       "5      30\n",
       "4      12\n",
       "Name: failure_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_tf[\"failure_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6059    1\n",
       "5397    1\n",
       "852     1\n",
       "Name: failure_type, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#definindo o y para o treino. Será o rótulo do aprendizado\n",
    "y = df_treino_tf[\"failure_type\"]\n",
    "y.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirando o y do conjunto de treino e as colunas que não seram utilizadas durante o processo de treinamento\n",
    "df_treino_tf.drop([\"failure_type\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1425</td>\n",
       "      <td>41.9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1558</td>\n",
       "      <td>42.4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_temperature_k  process_temperature_k  rotational_speed_rpm  torque_nm  \\\n",
       "0              298.1                  308.6                  1551       42.8   \n",
       "1              298.2                  308.7                  1408       46.3   \n",
       "2              298.2                  308.7                  1408       40.0   \n",
       "3              298.1                  308.6                  1425       41.9   \n",
       "4              298.1                  308.6                  1558       42.4   \n",
       "\n",
       "   tool_wear_min  \n",
       "0              0  \n",
       "1              3  \n",
       "2              9  \n",
       "3             11  \n",
       "4             14  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passo 4: Reescala dos dados\n",
    "\n",
    "Ao análisar os dados que serão considerados para análise percebe-se que os dados estão em escalas diferentes. \n",
    "\n",
    "Será utilizado uma técnica chamada StandardScaler. O cálculo da reescala é feito de forma independente entre cada coluna, de tal forma que a nova escala se dará entre 0 e 1 (ou -1 e 1 se houver valores negativos no dataset). O valor é diminuido da média e divido pelo desvio padrão.\n",
    "\n",
    "valor = (valor — média) / desvioPadão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino_nor = df_treino_tf.copy()\n",
    "df_treino_nor[['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm', 'torque_nm', 'tool_wear_min']] = StandardScaler().fit_transform(df_treino_tf[['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm', 'torque_nm', 'tool_wear_min']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>0.275525</td>\n",
       "      <td>-1.706224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.627282</td>\n",
       "      <td>-1.658872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898702</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>-0.005881</td>\n",
       "      <td>-1.564168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>-0.634531</td>\n",
       "      <td>0.185073</td>\n",
       "      <td>-1.532600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.948838</td>\n",
       "      <td>-0.935907</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.235324</td>\n",
       "      <td>-1.485247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6662</th>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.137521</td>\n",
       "      <td>0.545130</td>\n",
       "      <td>-1.221954</td>\n",
       "      <td>-1.516816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>-0.597884</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.375801</td>\n",
       "      <td>-1.061151</td>\n",
       "      <td>-1.485247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>-0.547747</td>\n",
       "      <td>-1.070317</td>\n",
       "      <td>0.533841</td>\n",
       "      <td>-0.829996</td>\n",
       "      <td>-1.437895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6665</th>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.730484</td>\n",
       "      <td>0.848386</td>\n",
       "      <td>-1.311623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666</th>\n",
       "      <td>-0.497611</td>\n",
       "      <td>-0.868702</td>\n",
       "      <td>-0.211207</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>-1.232703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6667 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "0             -0.948838              -0.935907              0.076652   \n",
       "1             -0.898702              -0.868702             -0.730484   \n",
       "2             -0.898702              -0.868702             -0.730484   \n",
       "3             -0.948838              -0.935907             -0.634531   \n",
       "4             -0.948838              -0.935907              0.116163   \n",
       "...                 ...                    ...                   ...   \n",
       "6662          -0.597884              -1.137521              0.545130   \n",
       "6663          -0.597884              -1.070317              0.375801   \n",
       "6664          -0.547747              -1.070317              0.533841   \n",
       "6665          -0.497611              -0.868702             -0.730484   \n",
       "6666          -0.497611              -0.868702             -0.211207   \n",
       "\n",
       "      torque_nm  tool_wear_min  \n",
       "0      0.275525      -1.706224  \n",
       "1      0.627282      -1.658872  \n",
       "2     -0.005881      -1.564168  \n",
       "3      0.185073      -1.532600  \n",
       "4      0.235324      -1.485247  \n",
       "...         ...            ...  \n",
       "6662  -1.221954      -1.516816  \n",
       "6663  -1.061151      -1.485247  \n",
       "6664  -0.829996      -1.437895  \n",
       "6665   0.848386      -1.311623  \n",
       "6666   0.014220      -1.232703  \n",
       "\n",
       "[6667 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_treino_nor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para manter o dataset de teste na mesma escala que o dataset de treino, também será utilizado StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_nor = df_teste_tf.copy()\n",
    "df_teste_nor[['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm', 'torque_nm', 'tool_wear_min']] = StandardScaler().fit_transform(df_teste_tf[['air_temperature_k', 'process_temperature_k', 'rotational_speed_rpm', 'torque_nm', 'tool_wear_min']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temperature_k</th>\n",
       "      <th>process_temperature_k</th>\n",
       "      <th>rotational_speed_rpm</th>\n",
       "      <th>torque_nm</th>\n",
       "      <th>tool_wear_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.257913</td>\n",
       "      <td>-0.970720</td>\n",
       "      <td>1.371494</td>\n",
       "      <td>-1.313901</td>\n",
       "      <td>-0.586211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.333272</td>\n",
       "      <td>0.317747</td>\n",
       "      <td>-0.029935</td>\n",
       "      <td>0.755363</td>\n",
       "      <td>1.312989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.407086</td>\n",
       "      <td>-1.106348</td>\n",
       "      <td>-0.444366</td>\n",
       "      <td>0.225551</td>\n",
       "      <td>-1.037660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.313147</td>\n",
       "      <td>-0.631650</td>\n",
       "      <td>0.700771</td>\n",
       "      <td>-0.394228</td>\n",
       "      <td>-0.617345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.023906</td>\n",
       "      <td>2.080913</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>-0.894050</td>\n",
       "      <td>-1.535811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>1.228314</td>\n",
       "      <td>1.267144</td>\n",
       "      <td>-1.284133</td>\n",
       "      <td>1.984926</td>\n",
       "      <td>1.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>0.333272</td>\n",
       "      <td>0.656818</td>\n",
       "      <td>-0.700658</td>\n",
       "      <td>1.215199</td>\n",
       "      <td>-0.259299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>0.382997</td>\n",
       "      <td>0.792446</td>\n",
       "      <td>-0.329852</td>\n",
       "      <td>-0.134321</td>\n",
       "      <td>1.141750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>1.377487</td>\n",
       "      <td>1.470587</td>\n",
       "      <td>-0.177167</td>\n",
       "      <td>-0.334250</td>\n",
       "      <td>-0.866421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>0.034925</td>\n",
       "      <td>-0.563835</td>\n",
       "      <td>0.793473</td>\n",
       "      <td>-1.213937</td>\n",
       "      <td>-0.197031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3333 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      air_temperature_k  process_temperature_k  rotational_speed_rpm  \\\n",
       "0             -1.257913              -0.970720              1.371494   \n",
       "1              0.333272               0.317747             -0.029935   \n",
       "2             -1.407086              -1.106348             -0.444366   \n",
       "3             -0.313147              -0.631650              0.700771   \n",
       "4              2.023906               2.080913              0.046407   \n",
       "...                 ...                    ...                   ...   \n",
       "3328           1.228314               1.267144             -1.284133   \n",
       "3329           0.333272               0.656818             -0.700658   \n",
       "3330           0.382997               0.792446             -0.329852   \n",
       "3331           1.377487               1.470587             -0.177167   \n",
       "3332           0.034925              -0.563835              0.793473   \n",
       "\n",
       "      torque_nm  tool_wear_min  \n",
       "0     -1.313901      -0.586211  \n",
       "1      0.755363       1.312989  \n",
       "2      0.225551      -1.037660  \n",
       "3     -0.394228      -0.617345  \n",
       "4     -0.894050      -1.535811  \n",
       "...         ...            ...  \n",
       "3328   1.984926       1.001645  \n",
       "3329   1.215199      -0.259299  \n",
       "3330  -0.134321       1.141750  \n",
       "3331  -0.334250      -0.866421  \n",
       "3332  -1.213937      -0.197031  \n",
       "\n",
       "[3333 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_teste_nor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 - Construção e treino dos modelos\n",
    "\n",
    "O objetivo dessa parte é testar qual o melhor modelo de dados a ser utilizado. Se deixa o modelo multiclass, com os rótulos originais do banco de dados, ou se agrupa todos os tipos de falhas em uma única coluna Failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_teste_df = df_teste_nor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25791266, -0.97071985,  1.37149439, -1.31390115, -0.58621105],\n",
       "       [ 0.33327219,  0.31774747, -0.02993524,  0.75536292,  1.31298946],\n",
       "       [-1.40708624, -1.10634799, -0.44436579,  0.22555135, -1.03766036],\n",
       "       ...,\n",
       "       [ 0.38299671,  0.79244596, -0.32985209, -0.13432067,  1.14175007],\n",
       "       [ 1.37748724,  1.47058665, -0.17716715, -0.33424956, -0.86642097],\n",
       "       [ 0.03492503, -0.56383543,  0.79347283, -1.2139367 , -0.19703062]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo o conjunto de treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_treino_nor, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Teste I - Sem balanceamento das classes\n",
    "\n",
    "Nesse teste as classes não serão balanceadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Classifier Light Gradient Boosting Machine (LightGBM)\n",
    "\n",
    "O primeiro classificador a ser testado será o LightGBM. Ele é **Gradient Boosting Framework** que utiliza da lógica de aprendizado por Árvore de Decisão. A vantagem desse classificador em relação aos demais é que a árvore cresce verticalmente, o algoritmo seleciona a \"folha que tenha o máximo delta **loss to grow**.\n",
    "\n",
    "Referência: B. Wang, Y. Wang, K. Qin and Q. Xia, \"Detecting Transportation Modes Based on LightGBM Classifier from GPS Trajectory Data,\" 2018 26th International Conference on Geoinformatics, Kunming, China, 2018, pp. 1-7, doi: 10.1109/GEOINFORMATICS.2018.8557149.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na análise exploratória dos dados foi detectado que a classe 'No Failure' tem um número expressivamente maior que as demais classes. Esse fator pode dar um problema no processo de classificação tendo em vista que o desbalanceamento entre as classes tende o resultado para classe mais expressiva, como no caso da base de dados é a classe 'No Failure'. Para testar essa hipótese será criado um modelo utilizando o classificador "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo os parâmetros\n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 6\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding data\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 916\n",
      "[LightGBM] [Info] Number of data points in the train set: 5333, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -4.438534\n",
      "[LightGBM] [Info] Start training from score -0.036472\n",
      "[LightGBM] [Info] Start training from score -4.868097\n",
      "[LightGBM] [Info] Start training from score -4.630425\n",
      "[LightGBM] [Info] Start training from score -6.384445\n",
      "[LightGBM] [Info] Start training from score -5.323573\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's multi_logloss: 0.117426\n",
      "[2]\tvalid_0's multi_logloss: 0.105359\n",
      "[3]\tvalid_0's multi_logloss: 0.0977981\n",
      "[4]\tvalid_0's multi_logloss: 0.0914299\n",
      "[5]\tvalid_0's multi_logloss: 0.0875975\n",
      "[6]\tvalid_0's multi_logloss: 0.0839455\n",
      "[7]\tvalid_0's multi_logloss: 0.0820688\n",
      "[8]\tvalid_0's multi_logloss: 0.0799691\n",
      "[9]\tvalid_0's multi_logloss: 0.0783538\n",
      "[10]\tvalid_0's multi_logloss: 0.0770582\n",
      "[11]\tvalid_0's multi_logloss: 0.0763113\n",
      "[12]\tvalid_0's multi_logloss: 0.0755619\n",
      "[13]\tvalid_0's multi_logloss: 0.0751292\n",
      "[14]\tvalid_0's multi_logloss: 0.0749321\n",
      "[15]\tvalid_0's multi_logloss: 0.0749846\n",
      "[16]\tvalid_0's multi_logloss: 0.0754356\n",
      "[17]\tvalid_0's multi_logloss: 0.0760024\n",
      "[18]\tvalid_0's multi_logloss: 0.0766251\n",
      "[19]\tvalid_0's multi_logloss: 0.0766567\n",
      "[20]\tvalid_0's multi_logloss: 0.0775036\n",
      "[21]\tvalid_0's multi_logloss: 0.0782972\n",
      "[22]\tvalid_0's multi_logloss: 0.0790674\n",
      "[23]\tvalid_0's multi_logloss: 0.0795984\n",
      "[24]\tvalid_0's multi_logloss: 0.0802447\n",
      "[25]\tvalid_0's multi_logloss: 0.0811104\n",
      "[26]\tvalid_0's multi_logloss: 0.0814855\n",
      "[27]\tvalid_0's multi_logloss: 0.0822588\n",
      "[28]\tvalid_0's multi_logloss: 0.083138\n",
      "[29]\tvalid_0's multi_logloss: 0.0844154\n",
      "[30]\tvalid_0's multi_logloss: 0.085187\n",
      "[31]\tvalid_0's multi_logloss: 0.0864092\n",
      "[32]\tvalid_0's multi_logloss: 0.0872522\n",
      "[33]\tvalid_0's multi_logloss: 0.0881006\n",
      "[34]\tvalid_0's multi_logloss: 0.0891048\n",
      "[35]\tvalid_0's multi_logloss: 0.0894298\n",
      "[36]\tvalid_0's multi_logloss: 0.0903379\n",
      "[37]\tvalid_0's multi_logloss: 0.0914181\n",
      "[38]\tvalid_0's multi_logloss: 0.0925275\n",
      "[39]\tvalid_0's multi_logloss: 0.0935861\n",
      "[40]\tvalid_0's multi_logloss: 0.0945706\n",
      "[41]\tvalid_0's multi_logloss: 0.0955374\n",
      "[42]\tvalid_0's multi_logloss: 0.0964031\n",
      "[43]\tvalid_0's multi_logloss: 0.0973122\n",
      "[44]\tvalid_0's multi_logloss: 0.0979266\n",
      "[45]\tvalid_0's multi_logloss: 0.0988393\n",
      "[46]\tvalid_0's multi_logloss: 0.0998367\n",
      "[47]\tvalid_0's multi_logloss: 0.100564\n",
      "[48]\tvalid_0's multi_logloss: 0.10106\n",
      "[49]\tvalid_0's multi_logloss: 0.101803\n",
      "[50]\tvalid_0's multi_logloss: 0.102449\n",
      "[51]\tvalid_0's multi_logloss: 0.103397\n",
      "[52]\tvalid_0's multi_logloss: 0.104543\n",
      "[53]\tvalid_0's multi_logloss: 0.105119\n",
      "[54]\tvalid_0's multi_logloss: 0.105786\n",
      "[55]\tvalid_0's multi_logloss: 0.106762\n",
      "[56]\tvalid_0's multi_logloss: 0.107358\n",
      "[57]\tvalid_0's multi_logloss: 0.108288\n",
      "[58]\tvalid_0's multi_logloss: 0.109681\n",
      "[59]\tvalid_0's multi_logloss: 0.11084\n",
      "[60]\tvalid_0's multi_logloss: 0.111979\n",
      "[61]\tvalid_0's multi_logloss: 0.113173\n",
      "[62]\tvalid_0's multi_logloss: 0.114551\n",
      "[63]\tvalid_0's multi_logloss: 0.115644\n",
      "[64]\tvalid_0's multi_logloss: 0.116977\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[65]\tvalid_0's multi_logloss: 0.118115\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[66]\tvalid_0's multi_logloss: 0.118687\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[67]\tvalid_0's multi_logloss: 0.119186\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[68]\tvalid_0's multi_logloss: 0.12003\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[69]\tvalid_0's multi_logloss: 0.121187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[70]\tvalid_0's multi_logloss: 0.122293\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[71]\tvalid_0's multi_logloss: 0.123429\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[72]\tvalid_0's multi_logloss: 0.124382\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[73]\tvalid_0's multi_logloss: 0.125632\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[74]\tvalid_0's multi_logloss: 0.127187\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[75]\tvalid_0's multi_logloss: 0.128616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[76]\tvalid_0's multi_logloss: 0.129993\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[77]\tvalid_0's multi_logloss: 0.131359\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[78]\tvalid_0's multi_logloss: 0.132686\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[79]\tvalid_0's multi_logloss: 0.133509\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[80]\tvalid_0's multi_logloss: 0.134756\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[81]\tvalid_0's multi_logloss: 0.136056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[82]\tvalid_0's multi_logloss: 0.13697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[83]\tvalid_0's multi_logloss: 0.137682\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[84]\tvalid_0's multi_logloss: 0.13887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[85]\tvalid_0's multi_logloss: 0.139579\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[86]\tvalid_0's multi_logloss: 0.140471\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[87]\tvalid_0's multi_logloss: 0.141142\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[88]\tvalid_0's multi_logloss: 0.14211\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[89]\tvalid_0's multi_logloss: 0.142777\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[90]\tvalid_0's multi_logloss: 0.144026\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[91]\tvalid_0's multi_logloss: 0.145399\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[92]\tvalid_0's multi_logloss: 0.146295\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[93]\tvalid_0's multi_logloss: 0.147269\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[94]\tvalid_0's multi_logloss: 0.148123\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[95]\tvalid_0's multi_logloss: 0.148763\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[96]\tvalid_0's multi_logloss: 0.149838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[97]\tvalid_0's multi_logloss: 0.150775\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[98]\tvalid_0's multi_logloss: 0.151415\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[99]\tvalid_0's multi_logloss: 0.152195\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.153451\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train,\n",
    "                 valid_sets=lgb_eval,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_lgb = model.predict(X_test)\n",
    "y_pred_lgb = argmax(y_pred_lgb, axis=1)\n",
    "cr = classification_report(y_test, y_pred_lgb)\n",
    "cm = confusion_matrix(y_test, y_pred_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.99      1.00      0.99      1293\n",
      "           2       0.78      0.64      0.70        11\n",
      "           3       0.67      0.55      0.60        11\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.98      1334\n",
      "   macro avg       0.57      0.50      0.53      1334\n",
      "weighted avg       0.98      0.98      0.98      1334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10    2    0    0    0    0]\n",
      " [   0 1288    1    3    0    1]\n",
      " [   0    4    7    0    0    0]\n",
      " [   0    4    1    6    0    0]\n",
      " [   0    3    0    0    0    0]\n",
      " [   0    4    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.983\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score %.3f\" % metrics.accuracy_score(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Classifier SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=1.0, random_state=1, kernel='linear')\n",
    " \n",
    "# Fit the model\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dani/anaconda3/envs/env_deep/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_svm = model.predict(X_test)\n",
    "y_pred_svm = argmax(y_pred_svm, axis=1)\n",
    "cr_svm = classification_report(y_test, y_pred_svm)\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.99      1.00      0.99      1293\n",
      "           2       0.78      0.64      0.70        11\n",
      "           3       0.67      0.55      0.60        11\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.98      1334\n",
      "   macro avg       0.57      0.50      0.53      1334\n",
      "weighted avg       0.98      0.98      0.98      1334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10    2    0    0    0    0]\n",
      " [   0 1288    1    3    0    1]\n",
      " [   0    4    7    0    0    0]\n",
      " [   0    4    1    6    0    0]\n",
      " [   0    3    0    0    0    0]\n",
      " [   0    4    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.983\n"
     ]
    }
   ],
   "source": [
    "# Measure the performance\n",
    "print(\"Accuracy score %.3f\" % metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Teste II - Com balanceamento das classes\n",
    "\n",
    "#### Nesse teste as classes serão balanceadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o conjunto de dados é pequeno, e o número de exemplos da classe 1 (No faiture) é bem expressiva em relação as demais optou-se por utilizar uma técnica de Over-sampling onde será replica os dados já existentes aumentando assim o número de ocorrências das classes minoritárias.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O número foi determinado com base no número classe com maior número de exemplos\n",
    "strategy = {0:5142, 1:5142, 2:5142, 3:5142, 4:5142, 5:5142}\n",
    "oversample = SMOTE(sampling_strategy=strategy)\n",
    "X_train_im, y_train_im = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=1, n=5142 (16.667%)\n",
      "Class=5, n=5142 (16.667%)\n",
      "Class=0, n=5142 (16.667%)\n",
      "Class=3, n=5142 (16.667%)\n",
      "Class=2, n=5142 (16.667%)\n",
      "Class=4, n=5142 (16.667%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = Counter(y_train_im)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y_train_im) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "plt.bar(counter.keys(), counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Classifier Light Gradient Boosting Machine (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding data\n",
    "lgb_train_im = lgb.Dataset(X_train_im, y_train_im)\n",
    "lgb_eval_im = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1275\n",
      "[LightGBM] [Info] Number of data points in the train set: 30852, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[LightGBM] [Info] Start training from score -1.791759\n",
      "[1]\tvalid_0's multi_logloss: 1.49216\n",
      "[2]\tvalid_0's multi_logloss: 1.30181\n",
      "[3]\tvalid_0's multi_logloss: 1.14571\n",
      "[4]\tvalid_0's multi_logloss: 1.0265\n",
      "[5]\tvalid_0's multi_logloss: 0.933469\n",
      "[6]\tvalid_0's multi_logloss: 0.856209\n",
      "[7]\tvalid_0's multi_logloss: 0.794695\n",
      "[8]\tvalid_0's multi_logloss: 0.739507\n",
      "[9]\tvalid_0's multi_logloss: 0.692272\n",
      "[10]\tvalid_0's multi_logloss: 0.648892\n",
      "[11]\tvalid_0's multi_logloss: 0.612347\n",
      "[12]\tvalid_0's multi_logloss: 0.581171\n",
      "[13]\tvalid_0's multi_logloss: 0.554574\n",
      "[14]\tvalid_0's multi_logloss: 0.524765\n",
      "[15]\tvalid_0's multi_logloss: 0.503223\n",
      "[16]\tvalid_0's multi_logloss: 0.476454\n",
      "[17]\tvalid_0's multi_logloss: 0.456887\n",
      "[18]\tvalid_0's multi_logloss: 0.436463\n",
      "[19]\tvalid_0's multi_logloss: 0.417132\n",
      "[20]\tvalid_0's multi_logloss: 0.39958\n",
      "[21]\tvalid_0's multi_logloss: 0.385955\n",
      "[22]\tvalid_0's multi_logloss: 0.371982\n",
      "[23]\tvalid_0's multi_logloss: 0.357666\n",
      "[24]\tvalid_0's multi_logloss: 0.344165\n",
      "[25]\tvalid_0's multi_logloss: 0.333248\n",
      "[26]\tvalid_0's multi_logloss: 0.320979\n",
      "[27]\tvalid_0's multi_logloss: 0.310125\n",
      "[28]\tvalid_0's multi_logloss: 0.299519\n",
      "[29]\tvalid_0's multi_logloss: 0.28932\n",
      "[30]\tvalid_0's multi_logloss: 0.281739\n",
      "[31]\tvalid_0's multi_logloss: 0.272657\n",
      "[32]\tvalid_0's multi_logloss: 0.26562\n",
      "[33]\tvalid_0's multi_logloss: 0.259727\n",
      "[34]\tvalid_0's multi_logloss: 0.253214\n",
      "[35]\tvalid_0's multi_logloss: 0.247464\n",
      "[36]\tvalid_0's multi_logloss: 0.239793\n",
      "[37]\tvalid_0's multi_logloss: 0.233303\n",
      "[38]\tvalid_0's multi_logloss: 0.226566\n",
      "[39]\tvalid_0's multi_logloss: 0.220457\n",
      "[40]\tvalid_0's multi_logloss: 0.218186\n",
      "[41]\tvalid_0's multi_logloss: 0.215173\n",
      "[42]\tvalid_0's multi_logloss: 0.209649\n",
      "[43]\tvalid_0's multi_logloss: 0.207657\n",
      "[44]\tvalid_0's multi_logloss: 0.203903\n",
      "[45]\tvalid_0's multi_logloss: 0.201874\n",
      "[46]\tvalid_0's multi_logloss: 0.198017\n",
      "[47]\tvalid_0's multi_logloss: 0.195285\n",
      "[48]\tvalid_0's multi_logloss: 0.193712\n",
      "[49]\tvalid_0's multi_logloss: 0.191038\n",
      "[50]\tvalid_0's multi_logloss: 0.189705\n",
      "[51]\tvalid_0's multi_logloss: 0.188881\n",
      "[52]\tvalid_0's multi_logloss: 0.187151\n",
      "[53]\tvalid_0's multi_logloss: 0.185905\n",
      "[54]\tvalid_0's multi_logloss: 0.185509\n",
      "[55]\tvalid_0's multi_logloss: 0.184733\n",
      "[56]\tvalid_0's multi_logloss: 0.184912\n",
      "[57]\tvalid_0's multi_logloss: 0.184254\n",
      "[58]\tvalid_0's multi_logloss: 0.184101\n",
      "[59]\tvalid_0's multi_logloss: 0.183666\n",
      "[60]\tvalid_0's multi_logloss: 0.181968\n",
      "[61]\tvalid_0's multi_logloss: 0.180873\n",
      "[62]\tvalid_0's multi_logloss: 0.18101\n",
      "[63]\tvalid_0's multi_logloss: 0.179548\n",
      "[64]\tvalid_0's multi_logloss: 0.178472\n",
      "[65]\tvalid_0's multi_logloss: 0.178597\n",
      "[66]\tvalid_0's multi_logloss: 0.178272\n",
      "[67]\tvalid_0's multi_logloss: 0.177292\n",
      "[68]\tvalid_0's multi_logloss: 0.176872\n",
      "[69]\tvalid_0's multi_logloss: 0.176309\n",
      "[70]\tvalid_0's multi_logloss: 0.175845\n",
      "[71]\tvalid_0's multi_logloss: 0.176015\n",
      "[72]\tvalid_0's multi_logloss: 0.17608\n",
      "[73]\tvalid_0's multi_logloss: 0.17568\n",
      "[74]\tvalid_0's multi_logloss: 0.174816\n",
      "[75]\tvalid_0's multi_logloss: 0.174902\n",
      "[76]\tvalid_0's multi_logloss: 0.17472\n",
      "[77]\tvalid_0's multi_logloss: 0.175045\n",
      "[78]\tvalid_0's multi_logloss: 0.175729\n",
      "[79]\tvalid_0's multi_logloss: 0.17604\n",
      "[80]\tvalid_0's multi_logloss: 0.176555\n",
      "[81]\tvalid_0's multi_logloss: 0.177003\n",
      "[82]\tvalid_0's multi_logloss: 0.17769\n",
      "[83]\tvalid_0's multi_logloss: 0.177921\n",
      "[84]\tvalid_0's multi_logloss: 0.177701\n",
      "[85]\tvalid_0's multi_logloss: 0.178462\n",
      "[86]\tvalid_0's multi_logloss: 0.179162\n",
      "[87]\tvalid_0's multi_logloss: 0.179375\n",
      "[88]\tvalid_0's multi_logloss: 0.180282\n",
      "[89]\tvalid_0's multi_logloss: 0.180932\n",
      "[90]\tvalid_0's multi_logloss: 0.180594\n",
      "[91]\tvalid_0's multi_logloss: 0.180144\n",
      "[92]\tvalid_0's multi_logloss: 0.180173\n",
      "[93]\tvalid_0's multi_logloss: 0.179885\n",
      "[94]\tvalid_0's multi_logloss: 0.179796\n",
      "[95]\tvalid_0's multi_logloss: 0.180746\n",
      "[96]\tvalid_0's multi_logloss: 0.18164\n",
      "[97]\tvalid_0's multi_logloss: 0.182107\n",
      "[98]\tvalid_0's multi_logloss: 0.182722\n",
      "[99]\tvalid_0's multi_logloss: 0.182723\n",
      "[100]\tvalid_0's multi_logloss: 0.183238\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(params,\n",
    "                 train_set=lgb_train_im,\n",
    "                 valid_sets=lgb_eval_im,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgb_im = model.predict(X_test)\n",
    "y_pred_lgb_im = argmax(y_pred_lgb_im, axis=1)\n",
    "cr_im = classification_report(y_test, y_pred_lgb_im)\n",
    "cm_im = confusion_matrix(y_test, y_pred_lgb_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.960\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score %.3f\" % metrics.accuracy_score(y_test, y_pred_lgb_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.99      0.97      0.98      1293\n",
      "           2       0.50      0.73      0.59        11\n",
      "           3       0.50      0.64      0.56        11\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.96      1334\n",
      "   macro avg       0.50      0.56      0.52      1334\n",
      "weighted avg       0.98      0.96      0.97      1334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12    0    0    0    0    0]\n",
      " [   0 1253    7    7   12   14]\n",
      " [   0    3    8    0    0    0]\n",
      " [   0    3    1    7    0    0]\n",
      " [   0    3    0    0    0    0]\n",
      " [   0    4    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Classifier SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_im = SVC(C=1.0, random_state=1, kernel='linear')\n",
    " \n",
    "# Fit the model\n",
    "svc_im.fit(X_train_im, y_train_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_im = model.predict(X_test)\n",
    "y_pred_svm_im = argmax(y_pred_svm_im, axis=1)\n",
    "cr_svm_im = classification_report(y_test, y_pred_svm_im)\n",
    "cm_svm_im = confusion_matrix(y_test, y_pred_svm_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        12\n",
      "           1       0.99      0.97      0.98      1293\n",
      "           2       0.50      0.73      0.59        11\n",
      "           3       0.50      0.64      0.56        11\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.96      1334\n",
      "   macro avg       0.50      0.56      0.52      1334\n",
      "weighted avg       0.98      0.96      0.97      1334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cr_svm_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  12    0    0    0    0    0]\n",
      " [   0 1253    7    7   12   14]\n",
      " [   0    3    8    0    0    0]\n",
      " [   0    3    1    7    0    0]\n",
      " [   0    3    0    0    0    0]\n",
      " [   0    4    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(cm_svm_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.960\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score %.3f\" % metrics.accuracy_score(y_test, y_pred_svm_im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Criar o csv do modelo com o melhor resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.DataFrame(y_pred_lgb_im, columns=['predictions']).to_csv('predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
